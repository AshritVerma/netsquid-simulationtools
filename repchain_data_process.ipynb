{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "import pandas\n", "import itertools\n", "import numpy as np\n", "from argparse import ArgumentParser\n", "from copy import deepcopy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from netsquid_simulationtools.repchain_data_combine import combine_data\n", "from netsquid_simulationtools.repchain_data_plot import plot_qkd_data, plot_fidelity_rate, plot_teleportation\n", "from netsquid_simulationtools.repchain_dataframe_holder import RepchainDataFrameHolder\n", "from netsquid_simulationtools.repchain_data_functions import end_to_end_fidelity, estimate_duration_per_success\n", "from netsquid_simulationtools.process_qkd import qber, estimate_bb84_secret_key_rate_from_data\n", "from netsquid_simulationtools.process_teleportation import teleportation_fidelity_optimized_over_local_unitaries_from_data, \\\n", "    estimate_average_teleportation_fidelity_from_data, determine_teleportation_fidelities_of_xyz_eigenstates_from_data, \\\n", "    estimate_minimum_teleportation_fidelity_over_xyz_eigenstates_from_data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_data(raw_data_dir=\"raw_data\", suffix=\".pickle\", output=\"processed_data.pickle\",\n", "                 csv_output_filename=\"output.csv\", process_duration=True, process_bb84=False,\n", "                 process_teleportation=False, process_fidelity=False, plot_processed_data=True):\n", "    \"\"\"Read different RepchainDataFrameHolder files with a common suffix and process them.\n", "    Which data processing functions are used can be specified using the different `process_` arguments of this function.\n", "    Parameters\n", "    ----------\n", "    raw_data_dir : str (optional)\n", "        Directory containing the data (pickle files containing\n", "        :class:`~netsquid_simulationtools.repchain_dataframe_holder.RepchainDataFrameHolder`s) to be processed.\n", "    suffix : str (optional)\n", "        Common ending of the files to be combined.\n", "        Files with this suffix are first combined into a single `RepchainDataFrameHolder`, then stored,\n", "        and then this combined `RepchainDataFrameHolder` is processed.\n", "    output : str (optional)\n", "        Filename with which to save the combined `RepchainDataFrameHolder`.\n", "    csv_output_filename : str (optional)\n", "        Filename with which to save the processed data.\n", "        The processed data is a `DataFrame` saved as a CSV file.\n", "    process_duration : bool (optional)\n", "        Set true if entanglement-generation duration should be calculated.\n", "    process_bb84 : bool (optional)\n", "        Set true if Quantum Bit Error Rate (QBER) should be estimated from the data, and used to calculate the\n", "        achievable secret-key rate when performing the BB84 protocol.\n", "        Requires `basis_A`, `basis_B`, `outcome_A` and `outcome_B` to be columns of the dataframe associated\n", "        with the `RepchainDataFrameHolder`.\n", "    process_teleportation : bool (optional)\n", "        Set true if quality of quantum teleportation using the entanglement in the data should be calculated.\n", "        The calculated quantities include average teleportation fidelity, minimum teleportation fidelity over\n", "        Pauli X, Y and Z eigenstates, and average teleportation fidelity if first an optimization over local unitary\n", "        transformations is performed.\n", "        Required `state` to be one of the columns of the dataframe associated with the `RepchainDataFrameHolder`.\n", "    process_fidelity : bool (optional)\n", "        Set true if end-to-end fidelity should be calculated.\n", "        Requires `state` to be a column of the dataframe associated with the `RepchainDataFrameHolder`.\n", "    plot_processed_data : Boolean (optional)\n", "        If True, plots the processed data with the plotting scripts available to the used processing types (default).\n", "        If False, nothing is plotted.\n", "    \"\"\"\n", "    processing_functions = []\n", "    if process_duration:\n", "        processing_functions.append(process_data_duration)\n", "    if process_bb84:\n", "        processing_functions.append(process_data_bb84)\n", "    if process_teleportation:\n", "        processing_functions.append(process_data_teleportation_fidelity)\n", "    if process_fidelity:\n", "        processing_functions.append(process_data_fidelity)\n", "    start_time = time.time()\n", "    combined_data = combine_data(raw_data_dir=raw_data_dir, suffix=suffix, output=output, save_output_to_file=True)\n", "    processed_data = process_repchain_dataframe_holder(combined_data, processing_functions=processing_functions)\n\n", "    # sort data by first scan_param\n", "    processed_data.sort_values(by=combined_data.varied_parameters[0], inplace=True)\n\n", "    # save processed data\n", "    processed_data.to_csv(csv_output_filename, index=False)\n", "    runtime = time.time() - start_time\n", "    print(f\"processed files in {raw_data_dir} with suffix {suffix} in {runtime} seconds\\n\"\n", "          f\"Used processing functions: {processing_functions}\")\n", "    if plot_processed_data:\n", "        filename = csv_output_filename\n", "        scan_param_name = combined_data.varied_parameters[0]\n", "        if process_bb84 and process_duration:\n", "            plot_qkd_data(filename=filename, scan_param_name=scan_param_name,\n", "                          scan_param_label=scan_param_name)\n", "        if process_teleportation:\n", "            plot_teleportation(filename=filename, scan_param_name=scan_param_name,\n", "                               scan_param_label=scan_param_name, show_duration=process_duration)\n", "        if process_fidelity:\n", "            plot_fidelity_rate(filename=filename, scan_param_name=scan_param_name,\n", "                               scan_param_label=scan_param_name)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_repchain_dataframe_holder(repchain_dataframe_holder, processing_functions, **kwargs):\n", "    \"\"\"Process a single :class:`RepchainDataFrameHolder` using some processing functions.\n", "    The `repchain_dataframe_holder`'s dataframe is split into multiple dataframes, one for each unique value of the\n", "    varied parameters.\n", "    Each dataframe is passed to each function in `processing_functions`, together with a dictionary `sim_params`\n", "    which contains all the simulation parameters used to obtain the data in that specific dataframe\n", "    (i.e. all the baseline parameters of `repchain_dataframe_holder` and the values of all varied parameters\n", "    corresponding to that part of the data).\n", "    The processing function is then expected to return a dictionary with processed information;\n", "    the keys of the dictionary should be the names of the different calculated quantities,\n", "    while the values should be the calculated values.\n", "    The only processed quantity automatically calculated by this function is the total number of successes\n", "    corresponding to each unique value of the varied parameters,\n", "    which is included under the name number_of_successes.\n", "    Parameters\n", "    ----------\n", "    repchain_dataframe_holder : :class:`~netsquid_simulationtools.repchain_dataframe_holder.RepchainDataFrameHolder`\n", "        Raw data to be processed.\n", "    processing_functions : list of functions\n", "        Functions used to process dataframes with data corresponding to a specific value of the simulation parameters.\n", "        Each function should take `dataframe` (a `DataFrame` with data as specified in the documentation of\n", "        :class:`~RepchainDataFrameHolder`) and `sim_params` (a dictionary with simulation parameter values\n", "        used to obtain data in `dataframe`) as arguments,\n", "        and output a dictionary holding names of processed quantities as keys and their calculated values as values.\n", "    Returns\n", "    -------\n", "    :class:`pd.DataFrame`\n", "        Dataframe containing processed data.\n", "        The dataframe has one row per unique value of varied parameters.\n", "        The columns are `number_of_successes`, `generation_duration_unit`, any varied parameters\n", "        and the processed quantities returned by the different `processing_functions`.\n", "    Notes\n", "    -----\n", "    The number_of_successes includes successes for which the basis choices are unequal.\n", "    \"\"\"\n\n", "    # access data in container\n", "    base_params = repchain_dataframe_holder.baseline_parameters\n", "    varied_params = repchain_dataframe_holder.varied_parameters\n\n", "    # TODO: think of a better way to deal with theses varied parameters\n", "    for key in [\"generation_duration\", \"number_of_successes\", \"sample_file\", \"current_round\", \"time_stamp\",\n", "                \"node_distance\"]:\n", "        if key in varied_params:\n", "            varied_params.remove(key)\n", "    varied_params_unique_values = []\n", "    for varied_param in varied_params:\n", "        varied_params_unique_values.append(repchain_dataframe_holder.dataframe[varied_param].unique().tolist())\n", "    processed_data = pandas.DataFrame()\n", "    for values in itertools.product(*varied_params_unique_values):\n", "        sim_params = deepcopy(base_params)\n", "        df = repchain_dataframe_holder.dataframe\n", "        varied_params_with_values = {}\n", "        for (varied_param, value) in zip(varied_params, values):\n", "            sim_params.update({varied_param: value})\n", "            varied_params_with_values.update({varied_param: value})\n", "            df = df[df[varied_param] == value]\n", "        df.drop(columns=varied_params)\n", "        if df.empty:\n", "            continue\n", "        processed_data_for_these_parameters = {\"number_of_successes\": [len(df.index)]}\n", "        for processing_function in processing_functions:\n", "            processed_data_for_these_parameters_by_this_processing_function = processing_function(dataframe=df,\n", "                                                                                                  sim_params=sim_params,\n", "                                                                                                  **kwargs)\n", "            processed_data_for_these_parameters.update(processed_data_for_these_parameters_by_this_processing_function)\n", "        processed_data_for_these_parameters.update(varied_params_with_values)\n", "        processed_data_for_these_parameters.update(\n", "            {\"generation_duration_unit\": repchain_dataframe_holder.baseline_parameters[\"generation_duration_unit\"]})\n", "        processed_data = processed_data.append(pandas.DataFrame(processed_data_for_these_parameters),\n", "                                               ignore_index=True)\n", "    return processed_data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_data_duration(dataframe, sim_params, **kwargs):\n", "    \"\"\"Calculate the entanglement-generation duration using entanglement-generation data.\n", "    The processed quantities calculated by this function are:\n", "    * duration_per_success, the average amount of time required to distribute a single entangled state.\n", "    * duration_per_success_error, the standard error in the estimate of `duration_per_success`.\n", "    This function is designed to be used with\n", "    :func:`~netsquid_simulationtools.repchain_data_process.process_repchain_dataframe_holder()`\n", "    Parameters\n", "    ----------\n", "    dataframe : :class:`pandas.DataFrame`\n", "        Entanglement-generation data in the format specified in the documentation of\n", "        :class:`~netsquid_simulationtools.repchain_dataframe_holder.RepchainDataFrameHolder`,\n", "        but all data must have been generated using the same simulation parameters.\n", "    sim_params : dict\n", "        Simulation parameters and their values used to generate the data held by `dataframe`.\n", "        Keys are names of simulation parameters, values are parameter values.\n", "    Returns\n", "    -------\n", "    dict\n", "        Processed quantity names as keys, their calculated values as values.\n", "    Notes\n", "    -----\n", "    For more information about how the generation duration per success is estimated, see\n", "    :class:`netsquid_simulationtools.repchain_data_functions.estimate_duration_per_success`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["    \n<br>\n", "    duration_per_success, duration_per_success_error = estimate_duration_per_success(dataframe=dataframe)<br>\n", "    processed_data = {<br>\n", "        \"duration_per_success\": [duration_per_success],<br>\n", "        \"duration_per_success_error\": [duration_per_success_error]}<br>\n", "    return processed_data<br>\n", "def process_data_bb84(dataframe, sim_params, sifting_factor=1, **kwargs):<br>\n", "  \nCalculate achievable secret-key rate using BB84 and Quantum-Bit Error Rate (QBER) from entanglement data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    The processed quantities calculated by this function are:\n", "    * sk_rate, the estimated secret-key rate achievable with the BB84 protocol using the entanglement-generation\n", "    statistics in the data.\n", "    * sk_rate_upper_bound, upper error bound on estimated secret-key rate.\n", "    * sk_rate_lower_bound, lower error bound on estimated secret-key rate.\n", "    * sk_error, standard error in estimated secret-key rate.\n", "    * Qber_z, the Quantum Bit Error Rate (QBER) in the Z basis.\n", "    * Qber_z_error, the standard error in the Quantum Bit Error Rate (QBER) in the Z basis.\n", "    * Qber_x, the Quantum Bit Error Rate (QBER) in the X basis.\n", "    * Qber_x_error, the standard error in the Quantum Bit Error Rate (QBER) in the X basis.\n", "    If `length` is defined in `sim_params`, the following quantities are also calculated:\n", "    * plob_bound, the PLOB bound on achievable secret-key rate without quantum repeater.\n", "    * tgw_bound, the TGW bound on achievable secret-key rate without quantum repeater.\n", "    This function is designed to be used with\n", "    :func:`~netsquid_simulationtools.repchain_data_process.process_repchain_dataframe_holder()`\n", "    Parameters\n", "    ----------\n", "    dataframe : :class:`pandas.DataFrame`\n", "        Entanglement-generation data in the format specified in the documentation of\n", "        :class:`~netsquid_simulationtools.repchain_dataframe_holder.RepchainDataFrameHolder`,\n", "        but all data must have been generated using the same simulation parameters.\n", "    sim_params : dict\n", "        Simulation parameters and their values used to generate the data held by `dataframe`.\n", "        Keys are names of simulation parameters, values are parameter values.\n", "    sifting_factor : float (optional)\n", "        Probability that both Alice and Bob use the same measurement basis.\n", "        Defaults to 1, representing fully-asymmetric BB84 (see notes below for explanation).\n", "        If both bases are chosen individually at random, `sifting_factor` should be set to 0.5.\n", "    Returns\n", "    -------\n", "    dict\n", "        Processed quantity names as keys, their calculated values as values.\n", "    Notes\n", "    -----\n", "    For more information about how the secret-key rate is estimated, see\n", "    :class:`netsquid_simulationtools.repchain_data_functions.estimate_bb84_secret_key_rate_from_data`.\n", "    For more information about how the QBER is estimated, see\n", "    :class:`netsquid_simulationtools.repchain_data_functions.qber`.\n", "    For more information about the PLOB and TGW bounds, see\n", "    :func:`~netsquid_simulationtools.repchain_data_process.secret_key_capacity()`.\n", "    \"\"\"\n\n", "    # calculate qber in X and Z\n", "    qber_z, qber_z_error = qber(dataframe, \"Z\")\n", "    qber_x, qber_x_error = qber(dataframe, \"X\")\n\n", "    # determine secret key rate in [bits/attempt]\n", "    secret_key_rate, skr_min, skr_max, skr_error = \\\n", "        estimate_bb84_secret_key_rate_from_data(dataframe, sifting_factor=sifting_factor)\n\n", "    # put all results in dictionary\n", "    processed_data = {\n", "        \"sk_rate\": [secret_key_rate],\n", "        \"sk_rate_upper_bound\": [skr_max],\n", "        \"sk_rate_lower_bound\": [skr_min],\n", "        \"sk_error\": [skr_error],\n", "        \"Qber_z\": [qber_z],\n", "        \"Qber_z_error\": [qber_z_error],\n", "        \"Qber_x\": [qber_x],\n", "        \"Qber_x_error\": [qber_x_error]}\n", "    if \"length\" in sim_params:\n", "        length = sim_params[\"length\"]\n", "        attenuation = sim_params[\"attenuation\"] if \"attenuation\" in sim_params else 0.25\n", "        if \"attenuation\" not in sim_params:\n", "            print(\"NOTE: capacity is based on default attenuation of 0.25 db/km, which may not correspond to \"\n", "                  \"attenuation used in simulations.\")\n\n", "        # calculate secret-key capacity\n", "        plob_bound, tgw_bound = secret_key_capacity(length=length, attenuation=attenuation)\n", "        processed_data.update({\"plob_bound\": [plob_bound],\n", "                               \"tgw_bound\": [tgw_bound]})\n", "    return processed_data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_data_teleportation_fidelity(dataframe, sim_params, **kwargs):\n", "    \"\"\"Calculate the achievable average fidelity of quantum teleportation achievable with data.\n", "    The processed quantities calculated by this function are:\n", "    * teleportation_fidelity_average, the teleportation fidelity averaged over all possible information (input) states,\n", "    using \"standard protocol\" described in documentation of\n", "    :func:`~netsquid-simulationtools.repchain_data_functions.determine_teleportation_output_state()`.\n", "    * teleportation_fidelity_average_error, standard error in teleportation_fidelity_average.\n", "    * teleportation_fidelity_minimum_xyz_eigenstate_index, eigenstate of Pauli X, Y and Z operators for which\n", "    the teleportation fidelity is the smallest if the state is used as information state.\n", "    Is a value of :class:`netsquid_simulationtools.repchain_data_functions.XYZEigenstateIndex`.\n", "    * teleportation_fidelity_minimum_xyz_eigenstates, the teleportation fidelity minimized over all eigenstates of\n", "    the Pauli X, Y and Z operators as information state. This is the teleportation fidelity when using\n", "    teleportation_fidelity_minimum_xyz_eigenstate_index as information state.\n", "    (which is generally not the same as the minimum over all information states).\n", "    * teleportation_fidelity_minimum_xyz_eigenstates_error, the standard error in\n", "    teleportation_fidelity_minimum_xyz_eigenstates.\n", "    * teleportation_fidelity_average_optimized_local_unitaries, the teleportation fidelity averaged over all possible\n", "    information (input) states using a protocol that is optimized over local unitary transformations.\n", "    For more information, see the documentation of\n", "    :func:`~netsquid_simulationtools.repchain_data_functions.teleportation_fidelity_optimized_over_local_unitaries()`.\n", "    This function is designed to be used with\n", "    :func:`~netsquid_simulationtools.repchain_data_process.process_repchain_dataframe_holder()`\n", "    Parameters\n", "    ----------\n", "    dataframe : :class:`pandas.DataFrame`\n", "        Entanglement-generation data in the format specified in the documentation of\n", "        :class:`~netsquid_simulationtools.repchain_dataframe_holder.RepchainDataFrameHolder`,\n", "        but all data must have been generated using the same simulation parameters.\n", "    sim_params : dict\n", "        Simulation parameters and their values used to generate the data held by `dataframe`.\n", "        Keys are names of simulation parameters, values are parameter values.\n", "    Returns\n", "    -------\n", "    dict\n", "        Processed quantity names as keys, their calculated values as values.\n", "    \"\"\"\n", "    fidelities_xyz_dataframe = determine_teleportation_fidelities_of_xyz_eigenstates_from_data(dataframe)\n", "    teleportation_fidelity_average, teleportation_fidelity_average_error = \\\n", "        estimate_average_teleportation_fidelity_from_data(fidelities_xyz_dataframe)\n", "    teleportation_fidelity_minimum_xyz_eigenstate_index, teleportation_fidelity_minimum_xyz_eigenstates, \\\n", "        teleportation_fidelity_minimum_xyz_eigenstates_error = \\\n", "        estimate_minimum_teleportation_fidelity_over_xyz_eigenstates_from_data(fidelities_xyz_dataframe)\n", "    teleportation_fidelity_average_optimized_local_unitaries = \\\n", "        teleportation_fidelity_optimized_over_local_unitaries_from_data(dataframe)\n", "    processed_data = {\n", "        \"teleportation_fidelity_average\": teleportation_fidelity_average,\n", "        \"teleportation_fidelity_average_error\": teleportation_fidelity_average_error,\n", "        \"teleportation_fidelity_minimum_xyz_eigenstate_index\": teleportation_fidelity_minimum_xyz_eigenstate_index,\n", "        \"teleportation_fidelity_minimum_xyz_eigenstates\": teleportation_fidelity_minimum_xyz_eigenstates,\n", "        \"teleportation_fidelity_minimum_xyz_eigenstates_error\": teleportation_fidelity_minimum_xyz_eigenstates_error,\n", "        \"teleportation_fidelity_average_optimized_local_unitaries\":\n", "            teleportation_fidelity_average_optimized_local_unitaries\n", "    }\n", "    return processed_data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_data_fidelity(dataframe, sim_params, **kwargs):\n", "    \"\"\"Calculate average end-to-end fidelity of entangled states.\n", "    The processed quantities calculated by this function are:\n", "    * fidelity, the average fidelity of end-to-end states to expected Bell state.\n", "    * fidelity_error, the standard error in the estimate of the fidelity.\n", "    This function is designed to be used with\n", "    :func:`~netsquid_simulationtools.repchain_data_process.process_repchain_dataframe_holder()`\n", "    Parameters\n", "    ----------\n", "    dataframe : :class:`pandas.DataFrame`\n", "        Entanglement-generation data in the format specified in the documentation of\n", "        :class:`~netsquid_simulationtools.repchain_dataframe_holder.RepchainDataFrameHolder`,\n", "        but all data must have been generated using the same simulation parameters.\n", "    sim_params : dict\n", "        Simulation parameters and their values used to generate the data held by `dataframe`.\n", "        Keys are names of simulation parameters, values are parameter values.\n", "    Returns\n", "    -------\n", "    dict\n", "        Processed quantity names as keys, their calculated values as values.\n", "    \"\"\"\n\n", "    # calculate fidelity and its error\n", "    fidelity, fidelity_error = end_to_end_fidelity(dataframe)\n\n", "    # put all results in dictionary\n", "    processed_data = {\n", "        \"fidelity\": [fidelity],\n", "        \"fidelity_error\": [fidelity_error],\n", "    }\n", "    return processed_data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def secret_key_capacity(length, attenuation=0.25):\n", "    \"\"\"Calculate Pirandola-Laurenza-Ottaviani-Banchi (PLOB) bound for lossy channels using two-way communication\n", "    (DOI: 10.1038/ncomms15043) (i.e. the maximum attainable for direct transmission) and the Takeoka-Guha-\n", "    Wilde (TGW) bound.\n", "    Parameters\n", "    ----------\n", "    length : float\n", "        Distance between end nodes performing QKD.\n", "    attenuation : float\n", "        Fiber loss in dB/km.\n", "    Return\n", "    ------\n", "    plob_bound : float\n", "        PLOB bound for secret-key-rate capacity for direct transmission in [bits/channel_use].\n", "    tgw_bound : float\n", "        Takeoka-Guha-Wilde bound for direct transmission in [bits/channel_use].\n", "    \"\"\"\n", "    if length < 0:\n", "        raise ValueError(\"Length cannot be negative.\")\n", "    transmissivity = 0.9999 if np.isclose(length, 0) else np.power(10, - attenuation * length / 10)\n", "    plob_bound = - np.log2(1 - transmissivity)  # sk capacity , PLOB bound in [bits/channel_use]\n", "    tgw_bound = np.log2((1 + transmissivity) / (1 - transmissivity))  # tgw bound [bits/channel_use]\n", "    return plob_bound, tgw_bound"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert_rdfh_with_number_of_rounds(rdfh):\n", "    \"\"\"Convert RepchainDataFramaHolder with outdated column name (`number_of_rounds` to `generation_duration`).\n", "    As of version 1.0.0, the way time scales are handled for RepchainDataFrameHolder has been changed. To unify\n", "    time scales across different platforms, RDFHs now have a column called `generation_duration`. The unit of this\n", "    column must be specified in the baseline parameters with `generation_duration_unit` and would usually have values\n", "    such as \"seconds\" or \"rounds\". To be able to work with old RDFHs containing `number_of_rounds` column, this method\n", "    can be used to fix how time scales are handled.\n", "    Parameters\n", "    ----------\n", "    rdfh : :obj:`nlblueprint.repchain_dataframe_holder.RepchainDataFrameHolder`\n", "        RepchainDataFrameHolder containing column with `number_of_rounds`.\n", "    Return\n", "    ------\n", "    rdfh : :obj:`nlblueprint.repchain_dataframe_holder.RepchainDataFrameHolder`\n", "        RepchainDataFrameHolder with abovementioned column converted into `generation_duration`.\n", "    \"\"\"\n", "    if not isinstance(rdfh, RepchainDataFrameHolder):\n", "        raise ValueError(\"Input parameter is not RepchainDataFrameHolder\")\n", "    if 'number_of_rounds' not in rdfh.dataframe.columns:\n", "        raise ValueError(\"Number of rounds is not in the RepchainDataFrameHolder\")\n\n", "    # rename column with `number_of_rounds`\n", "    rdfh.dataframe = rdfh.dataframe.rename(columns={'number_of_rounds': 'generation_duration'})\n\n", "    # update baseline parameters\n", "    rdfh.baseline_parameters.update({'generation_duration_unit': 'rounds'})\n", "    return rdfh"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    parser = ArgumentParser()\n", "    parser.add_argument(\"-d\", \"--raw_data_dir\", required=False, type=str, default=\"raw_data\",\n", "                        help=\"Directory containing the raw data (i.e. pickled RepchainDataFrameHolders)\"\n", "                             \"that should be processed.\")\n", "    parser.add_argument(\"-s\", \"--suffix\", required=False, type=str, default=\".pickle\",\n", "                        help=\"Common suffix of all the raw-data files in raw_data_dir that should be processed.\")\n", "    parser.add_argument(\"-o\", \"--output\", required=False, type=str, default=\"combined_data.pickle\",\n", "                        help=\"File to store combined data in. This is a pickled RepchainDataFrameHolder including\"\n", "                             \"all the results of all the RepchainDataFrameHolders included in processing.\")\n", "    parser.add_argument(\"-f\", \"--filename_csv\", required=False, type=str, default=\"output.csv\",\n", "                        help=\"File to store processing results in using CSV format.\")\n", "    parser.add_argument(\"--bb84\", dest=\"process_bb84\", action=\"store_true\", help=\"Perform BB84 processing.\")\n", "    parser.add_argument(\"-t\", \"--teleportation\", dest=\"process_teleportation_fidelity\", action=\"store_true\",\n", "                        help=\"Process achievable quantum-teleportation fidelity.\")\n", "    parser.add_argument(\"--fidelity\", dest=\"process_fidelity\", action=\"store_true\", help=\"Perform end-to-end \"\n", "                                                                                         \"fidelity processing.\")\n", "    parser.add_argument(\"--plot\", dest=\"plot\", action=\"store_true\", help=\"Plot the processing results.\")\n", "    args = parser.parse_args()\n", "    process_data(raw_data_dir=args.raw_data_dir, suffix=args.suffix, output=args.output,\n", "                 csv_output_filename=args.filename_csv, process_bb84=args.process_bb84,\n", "                 process_teleportation=args.process_teleportation_fidelity,\n", "                 process_fidelity=args.process_fidelity, plot_processed_data=args.plot)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}