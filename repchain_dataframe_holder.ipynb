{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas\n", "import numpy as np\n", "import pkg_resources\n", "from netsquid.qubits.ketstates import BellIndex"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from scipy import sparse"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class _StringKeyTypeDict(dict):\n", "    \"\"\"\n", "    A dictionary where the keys may only\n", "    be strings.\n", "    \"\"\"\n", "    def __setitem__(self, key, val):\n", "        if not isinstance(key, str):\n", "            raise TypeError(\"Key {} not a string\".format(key))\n", "        else:\n", "            super().__setitem__(key, val)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class RepchainDataFrameHolder:\n", "    \"\"\"Object holding results from simulations, together with metadata and methods for checking and adding new data.\n", "    Class of objects used to store results of quantum repeater chain simulations. Contains metadata about simulations\n", "    (which cannot be done by a pure pandas.DataFrame) and provides functionality to check and combine data.\n", "    Specifically, it contains properties indicating the the number of nodes in the simulated\n", "    repeater chain, the baseline parameters (parameters which are the same for all simulations of which results\n", "    are stored) and the total number of results held. It can test data it holds for validity and consistency,\n", "    and when data is added checks are performed first. The \"combine\" method can be used to combine multiple\n", "    objects of this class into one.\n", "    Parameters\n", "    ----------\n", "    number_of_nodes : int\n", "        Number of nodes used in repeater chain simulation\n", "        (including both repeater nodes and end nodes, but not heralding stations).\n", "    baseline_parameters : dict, optional\n", "        Parameters that have the same value for all simulations of which data is contained in this object.\n", "        A key-value pair consists of a parameter name and the corresponding value (must be hashable).\n", "    additional_packages : list of str, optional\n", "        Relevant additional packages that are used to generate the data and are added to the `packages`.\n", "        The version is automatically looked up based on the installed packages.\n", "        By default the netsquid and netsquid-simulationtools versions are added.\n", "    data : pandas.DataFrame or dict, optional\n", "        Actual simulation data. Must at least contain the following columns/keys:\n", "        - \"state\" (reduced density matrix or ket vector of quantum state delivered between end nodes (numpy.ndarray)),\n", "        - \"basis_A\" (measurement basis choice of Alice, must be \"X\", \"Y\" or \"Z\"),\n", "        - \"basis_B\" (measurement basis choice of Bob, must be \"X\", \"Y\" or \"Z\"),\n", "        - \"outcome_A\" (measurement result of Alice, must be 1 or -1),\n", "        - \"outcome_B\" (measurement result of Bob, must be 1 or -1),\n", "        - \"generation_duration\" (generation duration for the state, unit specified is in baseline parameters),\n", "        - \"midpoint_outcome_i\" for i = (0, 1, ..., number_of_nodes - 2)\n", "          (result of heralded entanglement generation, must be :class:`~netsquid.qubits.ketstates.BellIndex` indicating\n", "          Bell state that was projected on),\n", "        - \"swap_outcome_i\" for i = (0, 1, ..., number_of_nodes - 3),\n", "          (result of entanglement swap in repeater, must be :class:`~netsquid.qubits.ketstates.BellIndex` indicating\n", "          Bell state that was projected on),\n", "        - parameter_name for all parameters which are not constant for all results\n", "          (otherwise, they should be in baseline_parameters).\n", "        Any other column is optional.\n", "        Note that if any of the required columns is missing, no error or warning is raised.\n", "        This allows users to store e.g. only QKD measurement outcomes, or only state information, instead of both.\n", "    generation_duration_unit : str, optional\n", "        Unit for generation duration. This value is ignored if it is already specified in baseline parameters.\n", "        By default \"seconds\", i.e. `generation_duration` would hold time it takes to generate the state.\n", "    description : str\n", "    **kwargs : Any\n", "        Additional arguments that will be passed on to the constructor of the :obj:`pandas.DataFrame`\n", "    Notes\n", "    -----\n", "    Other functions to handle data held by objects of this class are not included as methods in order to\n", "    keep the class simple.\n", "    For Pauli indices, the following convention is used:\n", "    0 : 1 (identity)\n", "    1 : X\n", "    2 : Y\n", "    3 : Z\n", "    Parameter values must be hashable objects.\n", "    Example\n", "    -------\n", "    >>> data = {\"outcome_A\": [0, 0], \"basis_A\": [\"X\", \"Z\"],\n", "    >>>         \"outcome_B\": [1, 0], \"basis_B\": [\"Y\", \"Z\"],\n", "    >>>         \"generation_duration\": [12, 42],\n", "    >>>         \"midpoint_outcome_0\": [1, 2],\n", "    >>>         \"midpoint_outcome_1\": [3, 0],\n", "    >>>         \"swap_outcome_0\": [0, 1]}\n", "    >>>\n", "    >>> # We also add some other information that is not required by the\n", "    >>> # RepchainDataFrameHolder\n", "    >>> data[\"myowninfo\"] = [\"hello\", \"bye\"]\n", "    >>>\n", "    >>>\n", "    >>> h = RepchainDataFrameHolder(data=data)\n", "    >>>\n", "    >>> print(h.dataframe)\n", "    >>> # output:\n", "    >>> #outcome_A basis_A  outcome_B basis_B  generation_duration\n", "    >>> # midpoint_outcome_0  midpoint_outcome_1  swap_outcome_0 myowninfo\n", "    >>> #   0          0       X          1       Y                12\n", "    >>> # 1                   3               0         hello\n", "    >>> #   1          0       Z          0       Z                42\n", "    >>> # 2                   0               1         bye\n", "    >>>\n", "    The attribute `baseline_parameters` should be handled as a regular dictionary. Note that `generation_duration_unit`\n", "    will be automatically added in the init function if no baseline parameters are specified.\n", "    >>> # Initializing baseline parameters\n", "    >>> h.baseline_parameters.update({'prob_dark_count': 0.5})\n", "    >>> h.baseline_parameters['prob_gate_error'] = 0.1\n", "    >>> print(h.baseline_parameters)\n", "    >>> # output\n", "    >>> # {'prob_dark_count': 0.5, 'prob_gate_error': 0.1, 'generation_duration_unit': 'seconds'}\n", "    >>>\n", "    >>> # Removing baseline parameters\n", "    >>>\n", "    >>> del h.baseline_parameters['prob_gate_error']\n", "    >>> print(h.baseline_parameters)\n", "    >>> # output\n", "    >>> # {'prob_dark_count': 0.5}\n", "    >>>\n", "    If some important package is used to generate the data,\n", "    it can be added in the constructor.\n", "    The version is automatically looked up from the\n", "    installed packages.\n", "    >>> # Initialize RepChainDataFrameHolder with some additional package\n", "    >>> # By default, `netsquid` and `netsquid-simulationtools` are added\n", "    >>> h = RepchainDataFrameHolder(data=data, additional_packages=[\"netsquid-netconf\"])\n", "    >>> print(h.packages)\n", "    >>> # output\n", "    >>> # {'netsquid': [X.X.X], 'netsquid-simulatontools': [X.X.X], 'netsquid-netconf': [X.X.X]}\n", "    Develop notes: why use composition rather than inheritance\n", "    ----------------------------------------------------------\n", "    The main differences of this class with the :obj:`pandas.DataFrame` are:\n", "      * the metadata `baseline_parameters`\n", "      * the restriction that some column names must be in here\n", "    Unfortunately, the metadata which can be added as attribute to a :obj:`pandas.DataFrame` is not\n", "    preserved under appending, merging and concatenating such dataframes.\n", "    For this reason, we need this class.\n", "    It might seem more natural to subclass the :obj:`pandas.DataFrame`, with as main benefits that\n", "    the methods of the original dataframe are inherited and the user need not learn a new API.\n", "    This comes with new problems, however: many methods of the :obj:`pandas.DataFrame` *create* a new\n", "    DataFrame rather than changing the old one (e.g. `append`, `merge`, etc.) which makes the subclassing\n", "    not straightforward: each of these functions should be overridden so that the metadata is preserved.\n", "    In case not all functions are overridden, it is not a priori clear to the user whether the original\n", "    methods of :obj:`pandas.DataFrame` will work as expected also for a `RepchainDataFrame`. For this reason,\n", "    we decided to go for composition: we now have a `RepchainDataFrameHolder` which is not much more than\n", "    a basket for both the dataframe and the metadata.\n", "    \"\"\"\n", "    BASIS_TYPES = [\"X\", \"Y\", \"Z\"]\n", "    OUTCOME_TYPES = [0, 1]\n", "    PAULIS = [BellIndex.PHI_PLUS, BellIndex.PSI_PLUS, BellIndex.PSI_MINUS, BellIndex.PHI_MINUS]\n", "    COLUMN_NAMES_AND_CONSTRAINTS = \\\n", "        [(\"basis_A\", lambda x: x in RepchainDataFrameHolder.BASIS_TYPES),\n", "         (\"basis_B\", lambda x: x in RepchainDataFrameHolder.BASIS_TYPES),\n", "         (\"outcome_A\", lambda x: x in RepchainDataFrameHolder.OUTCOME_TYPES),\n", "         (\"outcome_B\", lambda x: x in RepchainDataFrameHolder.OUTCOME_TYPES),\n", "         (\"generation_duration\", lambda x: ((isinstance(x, int) or isinstance(x, float)) and x >= 0)),\n", "         (\"state\", lambda x: (isinstance(x, np.ndarray) or sparse.isspmatrix_csr(x)) and\n", "                             (x.shape[0] == x.shape[1] or (len(x.shape) == 2 and x.shape[1] == 1)))]\n", "    MIDPOINT_INDEX_COLUMN_NAMES_AND_CONSTRAINTS = \\\n", "        [(\"midpoint_outcome_\", lambda x: x in RepchainDataFrameHolder.PAULIS)]\n", "    NODE_INDEX_COLUMN_NAMES_AND_CONSTRAINTS = \\\n", "        [(\"swap_outcome_\", lambda x: x in RepchainDataFrameHolder.PAULIS)]\n", "    def __init__(self, data, number_of_nodes=None, baseline_parameters=None, additional_packages=None,\n", "                 description=None, generation_duration_unit=\"seconds\", **kwargs):\n\n", "        # define the input to the dataframe\n", "        if 'dtype' in kwargs:\n", "            raise Exception(\"Not allowed to set dtype\")\n", "        if 'columns' in kwargs:\n", "            raise Exception(\"Not allowed to set \\'columns\\'; use method `assign` instead\")\n", "        self.dataframe = pandas.DataFrame(data=data, **kwargs)\n", "        if number_of_nodes is None:\n", "            number_of_nodes = sum([\"swap_outcome\" in column for column in self.dataframe.columns]) + 2\n\n", "        # set number of nodes\n", "        if isinstance(number_of_nodes, float):\n", "            if number_of_nodes.is_integer():\n", "                number_of_nodes = int(number_of_nodes)\n", "        if not isinstance(number_of_nodes, int):\n", "            raise TypeError(\"number_of_nodes must be an integer\")\n\n", "        # use 'number_of_nodes' to determine columns\n", "        column_names = \\\n", "            [name for (name, __)\n", "             in self._column_names_and_constraints(number_of_nodes=number_of_nodes)]\n", "        self._column_names = column_names\n", "        self._number_of_nodes = number_of_nodes\n", "        self._description = description\n", "        self.baseline_parameters = _StringKeyTypeDict()\n", "        if baseline_parameters is not None:\n", "            self.baseline_parameters.update(baseline_parameters)\n", "        if self.baseline_parameters.get(\"generation_duration_unit\", None) is None:\n", "            self.baseline_parameters.update({\"generation_duration_unit\": generation_duration_unit})\n", "        self.packages = _StringKeyTypeDict()\n", "        # by default add netsquid and netsquid-simulationtools to the dictionary of baseline packages\n", "        packages = {'netsquid', 'netsquid-simulationtools'}\n", "        if additional_packages is not None:\n", "            # take the union of the two\n", "            packages = packages | set(additional_packages)\n", "        for package in packages:\n", "            # wrap the version of the package in a list for easy comparison during `combine()`\n", "            self.packages[package] = [pkg_resources.get_distribution(package).version]\n", "        self.check_dataframe_correctness()\n\n", "        # once the property `varied_parameters` is called once, we\n", "        # store its result in a variable in order to not have to\n", "        # compute it again\n", "        self._varied_parameters = None  # following the convention that\n", "        # each variable should be defined in __init__, even if it is given\n", "        # a different value directly afterwards:\n", "        self._reset_varied_parameters()\n", "    def _reset_varied_parameters(self):\n", "        self._varied_parameters = None\n", "    @property\n", "    def varied_parameters(self):\n", "        \"\"\"The names of the parameters that are not constant over all rows\n", "        of the data.\n", "        :rtype: list of str\n", "        \"\"\"\n", "        if self._varied_parameters is None:\n", "            # once the property `varied_parameters` is called once, we\n", "            # store its result in a variable in order to not have to\n", "            # compute it again\n", "            self._varied_parameters = []\n", "            columns_not_about_sim_results = \\\n", "                set(self.dataframe.columns) - set(self._column_names)\n", "            for column_name in columns_not_about_sim_results:\n", "                does_column_hold_single_element = \\\n", "                    len(list(set(self.dataframe[column_name].tolist()))) == 1\n", "                if not does_column_hold_single_element:\n", "                    self._varied_parameters.append(column_name)\n", "        return self._varied_parameters\n", "    @classmethod\n", "    def _column_names_and_constraints(cls, number_of_nodes):\n", "        return \\\n", "            cls.COLUMN_NAMES_AND_CONSTRAINTS + \\\n", "            [(name + str(midpoint_index), constraint)\n", "                for midpoint_index in range(number_of_nodes - 1)\n", "                for name, constraint in cls.MIDPOINT_INDEX_COLUMN_NAMES_AND_CONSTRAINTS] + \\\n", "            [(name + str(node_index), constraint)\n", "                for node_index in range(number_of_nodes - 2)\n", "                for name, constraint in cls.NODE_INDEX_COLUMN_NAMES_AND_CONSTRAINTS]\n", "    @property\n", "    def description(self):\n", "        return self._description\n", "    @property\n", "    def number_of_nodes(self):\n", "        return self._number_of_nodes\n", "    def update_dataframe_by_appending(self, check_for_correctness=True, **kwargs):\n", "        \"\"\"\n", "        Uses the `append` function of :obj:`pandas.DataFrame`\n", "        and subsequently checks correctness using\n", "        :obj:`nlblueprint.repchain_dataframe_holder.RepchainDataFrameHolder.check_dataframe_correctness`.\n", "        Parameters\n", "        ----------\n", "        **kwargs : Any\n", "            Passed on to :obj:`pandas.DataFrame.append`\n", "        Note\n", "        ----\n", "        By using `ignore_index=True` (see API of pandas.DataFrame), the indices of the rows\n", "        in the new data are ignored and the counting starts at the last index of\n", "        the original dataframe.\n", "        \"\"\"\n", "        self.dataframe = self.dataframe.append(**kwargs)\n", "        self._reset_varied_parameters()\n", "        if check_for_correctness:\n", "            self.check_dataframe_correctness()\n", "    @property\n", "    def number_of_results(self):\n", "        return self.dataframe.shape[0]\n", "    def check_dataframe_correctness(self):\n", "        \"\"\"\n", "        Check simulation data for validity and consistency.\n", "        Checks whether required columns are present and filled with expected kinds of data\n", "        and whether there are not too many midpoint/swap results.\n", "        \"\"\"\n", "        column_names_and_constraints = \\\n", "            self._column_names_and_constraints(number_of_nodes=self._number_of_nodes)\n", "        for index, row in self.dataframe.iterrows():\n", "            for column_name, column_constraint in column_names_and_constraints:\n", "                try:\n", "                    item = row[column_name]\n", "                    if not column_constraint(item):\n", "                        raise ValueError(f\"Row {index} contains {item} in column {column_name}\"\n", "                                         \", which does not have the correct type\")\n", "                except KeyError:\n", "                    # column was not found, in which case we decide to not\n", "                    # raise a warning. It is up to the user to define\n", "                    # which columns should be in the dataframe\n", "                    pass\n", "        column_names = set(self.dataframe.columns)\n", "        number_of_midpoint_substrings = 0\n", "        for column in column_names:\n", "            if 'midpoint_outcome_' in column:\n", "                number_of_midpoint_substrings += 1\n", "        if number_of_midpoint_substrings != self.number_of_nodes - 1:\n", "            raise ValueError(\"Incorrect number of midpoint outcomes\")\n", "        number_of_swap_substrings = 0\n", "        for column in column_names:\n", "            if 'swap_outcome_' in column:\n", "                number_of_swap_substrings += 1\n", "        if number_of_swap_substrings != self.number_of_nodes - 2:\n", "            raise ValueError(\"Incorrect number of swap outcomes\")\n", "    def copy_baseline_parameter_to_column(self, name,\n", "                                          remove_from_baseline=True):\n", "        \"\"\"\n", "        Adds the column `name` to the dataframe and fills the entries\n", "        with (copies of) the single value found in the baseline parameters.\n", "        Parameters\n", "        ----------\n", "        name : str\n", "            The parameter in `baseline_parameters`.\n", "        remove_from_baseline : bool\n", "            Whether the parameter will be removed from `baseline_parameters`\n", "            after the copying.\n", "        \"\"\"\n", "        val = self.baseline_parameters[name]\n", "        self.dataframe[name] = [val] * self.number_of_results\n", "        if remove_from_baseline:\n", "            del self.baseline_parameters[name]\n", "            self._reset_varied_parameters()\n", "    def combine(self, other, assert_equal_baseline_parameters=True, assert_equal_packages=True):\n", "        \"\"\"\n", "        Combines two :obj:`RepchainDataFrameHolder`\n", "        objects.\n", "        Parameters\n", "        ----------\n", "        other : :obj:`nlblueprint.repchain_dataframe_holder.RepchainDataFrameHolder`\n", "        assert_equal_baseline_parameters : bool\n", "            Use `assert_equal_baseline_parameters` to check for compatibility.\n", "            That is, if one combines two :obj:`RepchainDataFrameHolder`\n", "            objects and one has `probability_gate_error` set to 0.1 and\n", "            another to 0.2, then it will complain.\n", "            Default value is True.\n", "        assert_equal_packages : bool\n", "            Used to verify whether all the specified packages are equal.\n", "            If set to True, an Exception is raised if a package is missing or has a different version.\n", "            If set to False, it will only print a warning message and update the package version.\n", "            When a package is missing in one of the two :obj:`RepchainDataFrameHolder`s, the value `missing` will be\n", "            added to the version information.\n", "            When multiple different versions of the same package are used, they will be stored in a combined list.\n", "            Default value is True.\n", "        Example\n", "        -------\n", "        >>> first_data = \\\n", "        >>>        {\"outcome_A\": [0, 0], \"basis_A\": [\"X\", \"Z\"],\n", "        >>>         \"outcome_B\": [1, 0], \"basis_B\": [\"Y\", \"Z\"],\n", "        >>>         \"generation_duration\": [12, 42],\n", "        >>>         \"midpoint_outcome_0\": [1, 2],\n", "        >>>         \"midpoint_outcome_1\": [3, 0],\n", "        >>>         \"swap_outcome_0\": [0, 1],\n", "        >>>         \"birds\": [\"falcon\", \"finch\"]}\n", "        >>>\n", "        >>>\n", "        >>> first_holder = RepchainDataFrameHolder(data=data)\n", "        >>> first_holder.baseline_parameters = \\\n", "        >>>      {'prob_dark_count': 0.5, 'prob_gate_error': 0.1}\n", "        >>>\n", "        >>> second_data = \\\n", "        >>>        {\"outcome_A\": [1, 1], \"basis_A\": [\"Z\", \"Y\"],\n", "        >>>         \"outcome_B\": [0, 1], \"basis_B\": [\"X\", \"X\"],\n", "        >>>         \"generation_duration\": [33, 32],\n", "        >>>         \"midpoint_outcome_0\": [2, 1],\n", "        >>>         \"midpoint_outcome_1\": [0, 3],\n", "        >>>         \"swap_outcome_0\": [1, 0],\n", "        >>>         \"mammals\": [\"cow\", \"horse\"]}\n", "        >>>\n", "        >>> second_holder = RepchainDataFrameHolder(data=data2)\n", "        >>> second_holder.baseline_parameters = \\\n", "        >>>      {'prob_dark_count': 0.5, 'prob_gate_error': 0.2, 'fibre_length': 10}\n", "        >>>\n", "        >>> first_holder.combine(second_holder, assert_equal_baseline_parameters=False)\n", "        >>>\n", "        >>> print(first_holder)\n", "        >>> #Baseline parameters: {'prob_dark_count': 0.5, 'generation_duration_unit': 'seconds'}\n", "        >>> #Packages: {'netsquid': [X.X.X], 'netsquid-simulationtools': [X.X.X]}\n", "        >>> #  basis_A basis_B   birds  fibre_length mammals  midpoint_outcome_0\n", "        >>> # midpoint_outcome_1  generation_duration  outcome_A  outcome_B  prob_gate_error  swap_outcome_0\n", "        >>> #  0       X       Y  falcon           NaN     NaN\n", "        >>> # 1                   3                12          0          1              0.1               0\n", "        >>> #  1       Z       Z   finch           NaN     NaN\n", "        >>> # 2                   0                42          0          0              0.1               1\n", "        >>> #  2       Z       X     NaN          10.0     cow\n", "        >>> # 2                   0                33          1          0              0.2               1\n", "        >>> #  3       Y       X     NaN          10.0   horse\n", "        >>> # 1                   3                32          1          1              0.2               0\n", "        \"\"\"\n", "        if not isinstance(other, RepchainDataFrameHolder):\n", "            raise TypeError(\"{} is not a RepchainDataFrameHolder\")\n", "        if self.number_of_nodes != other.number_of_nodes:\n", "            raise Exception\n", "        if set(other._column_names) != set(self._column_names):\n", "            raise Exception\n", "        if assert_equal_baseline_parameters:\n", "            if set(self.baseline_parameters.items()) != set(other.baseline_parameters.items()):\n", "                raise Exception(\"Baseline parameters not equal\")\n\n", "        # compare packages both ways and print a warning or raise an Exception\n", "        package_differences = set(self.packages.keys()) ^ set(other.packages.keys())\n", "        if package_differences != set():\n", "            if assert_equal_packages:\n", "                raise VersionMismatchError(f\"Packages {package_differences} not found in both baseline packages. \"\n", "                                           f\"Self has packages {self.packages.keys()}, \"\n", "                                           f\"while other has {other.packages.keys()}.\")\n", "            # otherwise update the package version set by adding None to it\n", "            for package in package_differences:\n", "                print(f\"Warning: Package {package} not found in both baseline packages. \"\n", "                      \"Adding `missing` to list of versions.\")\n", "                # update the list of versions with `missing`\n", "                self_package_version = self.packages.get(package, [\"missing\"])\n", "                other_package_version = other.packages.get(package, [\"missing\"])\n", "                self.packages[package] = sorted(set(self_package_version + other_package_version),\n", "                                                reverse=True)\n", "        # now update version info for packages that are specified in both\n", "        for package in set(self.packages.keys()) & set(other.packages.keys()):\n", "            version, other_version = self.packages[package], other.packages[package]\n", "            if set(version) != set(other_version):\n", "                if assert_equal_packages:\n", "                    raise VersionMismatchError(f\"Version of package {package} not equal. \"\n", "                                               f\"Self uses {version}, while other uses {other_version}.\")\n", "                print(f\"Warning: multiple versions found of package {package}. Combining both versions into one list.\")\n", "                # print a warning statement and update the version information\n", "                self.packages[package] = sorted(set(version + other_version), reverse=True)\n\n", "        # copy all baseline parameters that are not part of both\n", "        # baselines to the data\n", "        for holder_A, holder_B in [(self, other), (other, self)]:\n", "            params_A = set(holder_A.baseline_parameters.items())\n", "            params_B = set(holder_B.baseline_parameters.items())\n", "            for (name, val) in params_A:\n", "                if (name, val) not in params_B:\n", "                    holder_A.copy_baseline_parameter_to_column(name=name)\n\n", "        # replace the current dataframe by the combined dataframe\n", "        self.update_dataframe_by_appending(other=other.dataframe, ignore_index=True, check_for_correctness=False)\n", "        self._reset_varied_parameters()\n", "    def __str__(self):\n", "        return f\"Baseline parameters: {self.baseline_parameters}\\n\" \\\n", "               f\"Packages: {self.packages}\\n{self.dataframe}\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class VersionMismatchError(Exception):\n", "    \"\"\"RepChainDataFrameHolder is combined with another one which has a different version for one of the packages.\"\"\"\n", "    pass"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}